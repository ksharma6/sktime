#!/usr/bin/env python3 -u
# copyright: sktime developers, BSD-3-Clause License (see LICENSE file)
"""Implements functions to be used in evaluating classification models."""

__author__ = ["ksharma6"]
__all__ = ["evaluate"]


PANDAS_MTYPES = ["pd.DataFrame", "pd.Series", "pd-multiindex", "pd_multiindex_hier"]


def evaluate(
    classifier,
    cv,
    X,
    y,
    # scoring#: Optional[Union[callable, list[callable]]] = None,
    # return_data: bool = False,
    # error_score: Union[str, int, float] = np.nan,
    # backend: Optional[str] = None,
    # backend_params: Optional[dict] = None,
):
    r"""Evaluate classifier using timeseries cross-validation.

    All-in-one statistical performance benchmarking utility for classifiers
    which runs a simple backtest experiment and returns a summary pd.DataFrame.

    The experiment run is the following:

    Train and test fold indices are generated by ``cv.split(X)``.

    1. Initialize the counter to ``i = 1``
    2. Fit the ``classifier`` to training set S_i.
    3. Use the ``classifier`` to make a prediction ``y_pred`` on test set T_i.
    4. Compute the ``scoring`` function on ``y_pred`` versus test set T_i.
    5. If ``i == K``, terminate, otherwise
    6. Set ``i = i + 1``
    7. Go to 3

    Results returned in this function's return are:

    * results of ``scoring`` calculations, from 4,  in the ``i``-th loop
    * runtimes for fitting and/or predicting, from 2, 3, in the ``i``-th loop
    * cutoff state of ``classifier``, at 3, in the ``i``-th loop
    * :math:`y_{train, i}`, :math:`y_{test, i}`, ``y_pred`` (optional)

    A distributed and-or parallel back-end can be chosen via the ``backend`` parameter.

    Parameters
    ----------
    classifier : sktime BaseClassifier descendant (concrete classifier)
        sktime classifier to benchmark
    cv : sklearn ShuffleSplit
       Provides train/test indices to split ``X`` and y into train and test sets.
    X : sktime compatible time series panel data container, Panel scitype, e.g.,
        pd-multiindex: pd.DataFrame with columns = variables,
        numpy3D: 3D np.array (any number of dimensions, equal length series)
        of shape [n_instances, n_dimensions, series_length]
        or of any other supported Panel mtype
        for list of mtypes, see datatypes.SCITYPE_REGISTER
        for specifications, see examples/AA_datatypes_and_datasets.ipynb
    y : sktime compatible tabular data container, Table scitype
        numpy1D iterable, of shape [n_instances]
    scoring : subclass of sklearn.metrics or list of same,
        default=None. Used to get a score function that takes y_pred and y_test
        arguments and accept y_train as keyword argument.
        If None, then uses scoring = accuracy_score().
    return_data : bool, default=False
        Returns three additional columns in the DataFrame, by default False.
        The cells of the columns contain each a pd.Series for y_train,
        y_pred, y_test.
    error_score : "raise" or numeric, default=np.nan
        Value to assign to the score if an exception occurs in estimator fitting. If set
        to "raise", the exception is raised. If a numeric value is given,
        FitFailedWarning is raised.
    backend : {"dask", "loky", "multiprocessing", "threading"}, by default None.
        Runs parallel evaluate if specified and ``strategy`` is set as "refit".

        - "None": executes loop sequentally, simple list comprehension
        - "loky", "multiprocessing" and "threading": uses ``joblib.Parallel`` loops
        - "joblib": custom and 3rd party ``joblib`` backends, e.g., ``spark``
        - "dask": uses ``dask``, requires ``dask`` package in environment
        - "dask_lazy": same as "dask",
          but changes the return to (lazy) ``dask.dataframe.DataFrame``.

        Recommendation: Use "dask" or "loky" for parallel evaluate.
        "threading" is unlikely to see speed ups due to the GIL and the serialization
        backend (``cloudpickle``) for "dask" and "loky" is generally more robust
        than the standard ``pickle`` library used in "multiprocessing".

    backend_params : dict, optional
        additional parameters passed to the backend as config.
        Directly passed to ``utils.parallel.parallelize``.
        Valid keys depend on the value of ``backend``:

        - "None": no additional parameters, ``backend_params`` is ignored
        - "loky", "multiprocessing" and "threading": default ``joblib`` backends
          any valid keys for ``joblib.Parallel`` can be passed here, e.g., ``n_jobs``,
          with the exception of ``backend`` which is directly controlled by ``backend``.
          If ``n_jobs`` is not passed, it will default to ``-1``, other parameters
          will default to ``joblib`` defaults.
        - "joblib": custom and 3rd party ``joblib`` backends, e.g., ``spark``.
          any valid keys for ``joblib.Parallel`` can be passed here, e.g., ``n_jobs``,
          ``backend`` must be passed as a key of ``backend_params`` in this case.
          If ``n_jobs`` is not passed, it will default to ``-1``, other parameters
          will default to ``joblib`` defaults.
        - "dask": any valid keys for ``dask.compute`` can be passed,
          e.g., ``scheduler``

    Returns
    -------
    results : pd.DataFrame or dask.dataframe.DataFrame
       DataFrame that contains several columns with information regarding each
       refit/update and prediction of the classifier.
       Row index is TimeSeriesSplit index of train/test fold in ``cv``.
       Entries in the i-th row are for the i-th train/test split in ``cv``.
       Columns are as follows:

        - test_{scoring.name}: (float) Model performance score. If ``scoring`` is a
        list,
        then there is a column withname ``test_{scoring.name}`` for each scorer.

        - fit_time: (float) Time in sec for ``fit`` or ``update`` on train fold.
        - pred_time: (float) Time in sec to ``predict`` from fitted estimator.
        - y_train: (pd.Series) only present if see ``return_data=True``
        train fold of the i-th split in ``cv``, used to fit/update the classifier.

        - y_pred: (pd.Series) present if see ``return_data=True``
        classifies from fitted classifier for the i-th test fold indices of ``cv``.

        - y_test: (pd.Series) present if see ``return_data=True``
        testing fold of the i-th split in ``cv``, used to compute the metric.
    """
    pass
